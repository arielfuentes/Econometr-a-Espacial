---
title: "Logistic Regression - Claudio Álvarez"
output:
  html_document:
    toc: true
    toc_float: true
---
## 1) Apertura de datos

Se utilizará la fuente de datos "Heart Disease" (comúnmente utilizada para pruebas de ML)
La descripción de sus campos será la siguiente:

* "age" : age
* "sex":  sex
  - 0 = female
  - 1 = male
* "cp": chest pain
  - 1 = typical angina
  - 2 = atypical angina
  - 3 = non-anginal pain
  - 4 = asymptomatic
* "trestbps": resting blood pressure (in mm Hg)
*  "chol": serum cholestoral in mg/dl
* "fbs": fasting blood sugar if less than 120 mg/dl
  - 1 = TRUE
  - 0 = FALSE
* "restecg": resting electrocardiographic results
  - 1 = normal
  - 2 = having ST-T wave abnormality
  - 3 = showing probable or definite left ventricular hypertrophy
* "thalach": maximum heart rate achieved
* "exang": exercise induced angina
  - 1 = yes
  - 0 = no
* "oldpeak": ST depression induced by exercise relative to rest
* "slope": the slope of the peak exercise ST segment
  - 1 = upsloping
  - 2 = flat
  - 3 = downsloping
* "ca": number of major vessels (0-3) colored by fluoroscopy
* "thal": this is short of thalium heart scan
  - 3 = normal (no cold spots)
  - 6 = fixed defect (cold spots during rest and exercise)
  - 7 = reversible defect (when cold spots only appear during exercise)
*  "hd": (the predicted attribute) - diagnosis of heart disease
    - 0 = if less than or equal to 50% diameter narrowing
    - 1 = if greater than 50% diameter narrowing


```{r setup}
library(readr)
data <- read_delim("heart_desease.csv", 
    ";", escape_double = FALSE, trim_ws = TRUE)
data = as.data.frame(data[,c(2:ncol(data))])
str(data)
summary(data)
```

## 2) Arreglo de datos

```{r}
## Convertir "?"s a NAs
data[data == "?"] <- NA
```

```{r}
## Agregar factores para variables y transformar su formato

data[data$sex == 0,]$sex <- "F"
data[data$sex == 1,]$sex <- "M"
data$sex <- as.factor(data$sex)
```

```{r}
data$cp <- as.factor(data$cp)
data$fbs <- as.factor(data$fbs)
data$restecg <- as.factor(data$restecg)
data$exang <- as.factor(data$exang)
data$slope <- as.factor(data$slope)
```

```{r}
data$ca <- as.integer(data$ca) # Como esta variable posee inicalmente "?"s 
# R asume los registros como string
# Pero sabemos que deben ser enteros y factores
data$ca <- as.factor(data$ca)
```

```{r}
data$thal <- as.integer(data$thal) # Aquí ocurre lo mismo
data$thal <- as.factor(data$thal)
```

```{r}
## La siguiente línea reemplaza valores por descripciones
data$hd <- ifelse(test=data$hd == 0, yes="Healthy", no="Unhealthy")
data$hd <- as.factor(data$hd) # Y convierte a factor
```

```{r}
str(data) ## Se verifica que las columnas son correctas
```

```{r}
## Determinar cuantas filas contienen "NA"
## Si corresponde a una pequeña cantidad se pueden eliminar para simplificar el ejercicio
## Sino, se pueden imputar ¿qué métodos de imputación existen?

nrow(data[is.na(data$ca) | is.na(data$thal),])
data[is.na(data$ca) | is.na(data$thal),]
## Entonces 6 de 303 filas contienen "NA" (2%). Por lo que se eliminan
nrow(data)
data <- data[!(is.na(data$ca) | is.na(data$thal)),]
nrow(data)
```

## 3) Análisis de variabilidad

Ahora se puede realizar control de calidad para asegurarnos que todos los factores
son representados por personas con y sin problemas de corazon (hd)


```{r}
## Verificamos que muestras de pacientes con o sin problemas correspondan a distintos sexos

## Si solamente hombres presentan problemas, probablemente conviene remover todas las muestras de mujeres del modelo
xtabs(~ hd + sex, data=data)
```

```{r}
## Verificamos que los niveles de dolor de pecho es representado por varios pacientes
xtabs(~ hd + cp, data=data)
```

```{r}
## Se repite el proceso para el resto
xtabs(~ hd + fbs, data=data)
```

```{r}
## Aquí observaremos que hay baja representatividad, esto podría afectar al modelo
xtabs(~ hd + restecg, data=data)
```

```{r}
xtabs(~ hd + exang, data=data)
```

```{r}
xtabs(~ hd + slope, data=data)
```

```{r}
xtabs(~ hd + ca, data=data)
```

```{r}
xtabs(~ hd + thal, data=data)
```

## 4) Calibración de modelo simple (Logistic Regression)

Comenzaremos con un modelo simple y verificar si sexo (femenino/masculino) es un buen predictor

Mirando los datos iniciales

```{r}
xtabs(~ hd + sex, data=data)
```

* La mayoría de las mujeres son saludables y la mayoría de hombres no lo son

* Ser mujer tiende a reducir la probabilidad de no ser saludable

* Lo contrario ocurre con hombres

Aplicando  la regressión

```{r}
logistic <- glm(hd ~ sex, data=data, family="binomial")
summary(logistic)
```

* Primero, se observa la formula llamada
* Segundo, se observa un resumen de la desviación de residuos, se ven bien dado que se centran en 0 y en general simétricos

Viendo los coeficientes:

* El modelo corresponde a: hd = -1.0438 + 1.2737 x El paciente es hombre
* Esta última variable, singifica que equivale a 0 cuando el paciente es femenino y 1 cuando es masculino
* Entonces, si estamos prediciendo para una mujer la ecuación será: hd = -1.0438 + 1.2737 x 0
* Por lo tanto, la razón de probabilidad logarítmica de que una mujer presente problemas es de -1.0438

Nota: recordar la tabla inicial 

```{r}
## 25: mujeres no saludables
## 75: mujeres saludables
female.log.odds <- log(25 / 71)
female.log.odds
```

* De predecir para hombres, la ecuación sería: hd = -1.0438 + 1.2737 x 1
* Donde el segundo término representa la razón de probabilidad logarítmica de que un hombre presente problemas
* En otras palabras, el segundo término es la razón de probabilidad logarítmica de que un hombre presente problemas al corazón sobre la razón de probabilidad logarítmica de que una mujer presente problemas al corazon

```{r}
male.log.odds.ratio <- log((112 / 89) / (25/71))
male.log.odds.ratio
```

También podemos ver:
* El error
* z value (Wald's test)
* p-values : ambos son bajo 0.05 por lo tanto; ambos estadísticamente significativos


Es importante observar el AIC (Akaike Information Criterion)
Que en este caso es la desviación del residuo ajustado para el número de paraámetros del modelo
EL AIC puede ser utilizado para comparar modelos


Veamos la predicción del modelo dado que un paciente es femenino o masculino

```{r}
predicted.data <- data.frame(
  probability.of.hd=logistic$fitted.values,
  sex=data$sex)
```

Y generamos una visualiazción gráfica

```{r}
library(ggplot2)
ggplot(data=predicted.data, aes(x=sex, y=probability.of.hd)) +
  geom_point(aes(color=sex), size=5) +
  xlab("Sex") +
  ylab("Predicted probability of getting heart disease")
```

Dado que solo utilizamos dos probabilidades, podemos realizar una tabla resumen

```{r}
xtabs(~ probability.of.hd + sex, data=predicted.data)
```

## 5) Calibración de modelo completo

```{r}
logistic <- glm(hd ~ ., data=data, family="binomial")
summary(logistic)
```

* Vemos que "age" no es muy útil ya que tiene un alto p-value
* Sin embargo, sabemos que la edad promedio es de 56, la mayoría es de ese rango etario, lo que explica por que "age" no es muy util como variable
* "genderM" sigue siendo bueno

Nota: explique el resto de coeficientes

* También notamos que la desviación de residuos y AIC son mucho menor


Calculemos el "Pseudo R-squared" and its p-value
```{r}
ll.null <- logistic$null.deviance/-2
ll.proposed <- logistic$deviance/-2
```

Calculemos McFadden's Pseudo R^2 = [ LL(Null) - LL(Proposed) ] / LL(Null)

```{r}
(ll.null - ll.proposed) / ll.null
```

Ahora calculamos el p-value para el R^2 utilizando una distribución chi-cuadrado

```{r}
1 - pchisq(2*(ll.proposed - ll.null), df=(length(logistic$coefficients)-1))
```

Graficamos

```{r}
predicted.data <- data.frame(
  probability.of.hd=logistic$fitted.values,
  hd=data$hd)

predicted.data <- predicted.data[
  order(predicted.data$probability.of.hd, decreasing=FALSE),]
predicted.data$rank <- 1:nrow(predicted.data)

## Graficamos la probabilidad predicha para cada muestra de paciente que presenta problemas al corazon y le entregamos una paleta de color según si efectivamente presentan o no problemas

ggplot(data=predicted.data, aes(x=rank, y=probability.of.hd)) +
  geom_point(aes(color=hd), alpha=1, shape=4, stroke=2) +
  xlab("Index") +
  ylab("Predicted probability of getting heart disease")
```


Como último análisis se lleva a cabo en base a la visualización del rendimiento de los clasificadores de puntuación, el cual consiste en un gráfico a partir de la estimación de resultados de forma verdadera (eje X) y falsa (eje Y), por lo tanto si los resultados obtenidos de la predicción del modelo son verdaderos, es decir coinciden con los originales se obtendrá una recta paralela a las abscisas (eje x) 
con valor igual a 1, caso contrario, se obtendrá una recta paralela a las ordenadas (eje y) con valor igual a 1

De la curva generada se calcula el área bajo la curva, está varía entre 0 y 1; entonces si su valor es mayor a 0.5 indica que el modelo utilizado podría tener una buena capacidad de predicción. Si es igual a 1 indica que su predicción es totalmente buena. Si es menor a 0.5 indica que su predicción podría no ser adecuada. 

```{r}
library(ROCR)

## Gráfico
validation=predict(logistic,data,type="response")
pr <- prediction(validation, data$hd)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

## Área bajo la curva
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc

```

--------------------

Fuente: https://www.youtube.com/watch?v=C4N3_XJJ-jU&ab_channel=StatQuestwithJoshStarmer